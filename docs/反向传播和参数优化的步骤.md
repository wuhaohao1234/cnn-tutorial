在训练循环中，进行模型的前向传播、损失计算、反向传播和参数优化是典型的步骤。以下是一个简化的示例代码，演示了这些步骤：

```python
import torch
import torch.nn as nn
import torch.optim as optim

# 创建模型实例（假设模型名为 SimpleCNN）
model = SimpleCNN()

# 定义损失函数（交叉熵损失）
criterion = nn.CrossEntropyLoss()

# 定义优化器（随机梯度下降SGD），指定学习率
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 假设有训练数据集 train_loader，其中包含输入数据 input_data 和对应的标签 target

# 定义训练循环参数
num_epochs = 10

for epoch in range(num_epochs):
    # 模型训练模式
    model.train()

    # 遍历训练数据集
    for input_data, target in train_loader:
        # 清零梯度
        optimizer.zero_grad()

        # 前向传播
        output = model(input_data)

        # 计算损失
        loss = criterion(output, target)

        # 反向传播
        loss.backward()

        # 参数优化
        optimizer.step()

    # 打印当前epoch的损失
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')

# 训练完成后，模型的参数已经更新，可以用于预测或者进一步的评估。
```

上述代码中，`train_loader` 是一个用于加载训练数据的数据加载器，它每次返回一个小批次的数据。在每个训练迭代中，模型接收输入数据，进行前向传播，计算损失，然后通过反向传播更新模型的参数。这个过程重复进行，直到达到指定的训练轮数（`num_epochs`）。在每个epoch结束时，打印当前epoch的损失，以便了解模型的训练进度。

需要注意的是，在实际应用中，还需要考虑验证集的使用、学习率调整等因素，以更好地训练和优化模型。